import discord
from discord import app_commands
from discord.ext import commands
import os
import aiohttp
import re

class AIChat(commands.Cog):
    ai_group = app_commands.Group(name="ai", description="GitHub Native çŸ¥èƒ½ä¸­æ¢")

    def __init__(self, bot):
        self.bot = bot
        # GitHubã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ä½¿ç”¨ï¼ˆGitHub Actionsãªã‚‰è‡ªå‹•ã§æ¸¡ã•ã‚Œã‚‹MY_GITHUB_TOKENç­‰ï¼‰
        self.token = os.getenv("MY_GITHUB_TOKEN") or os.getenv("HUGGINGFACE_TOKEN")
        # GitHub Models ã®å®‰å®šã—ãŸã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
        self.endpoint = "https://models.inference.ai.azure.com/chat/completions"

    async def generate_response(self, prompt):
        if not self.token:
            return "âŒ GitHubãƒˆãƒ¼ã‚¯ãƒ³ãŒæœªè¨­å®šã§ã™ã€‚"

        headers = {
            "Authorization": f"Bearer {self.token}",
            "Content-Type": "application/json"
        }

        # Llama 3.1 70B (è¶…é«˜æ€§èƒ½ãƒ»ç„¡æ–™) ã‚’æŒ‡å®š
        payload = {
            "messages": [
                {"role": "system", "content": "ã‚ãªãŸã¯æ”¯æ´AIã€Rb m/25Eã€ã§ã™ã€‚æ—¥æœ¬èªã§å›ç­”ã—ã¦ãã ã•ã„ã€‚"},
                {"role": "user", "content": prompt}
            ],
            "model": "meta-llama-3.1-70b-instruct",
            "max_tokens": 1000
        }

        try:
            async with aiohttp.ClientSession() as session:
                async with session.post(self.endpoint, headers=headers, json=payload) as resp:
                    result = await resp.json()
                    
                    if resp.status == 200:
                        return result['choices'][0]['message']['content']
                    else:
                        error_details = result.get('error', {}).get('message', 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼')
                        return f"âš ï¸ GitHub AIã‚¨ãƒ©ãƒ¼ ({resp.status}): {error_details}"
        except Exception as e:
            return f"âš ï¸ é€šä¿¡å¤±æ•—: {str(e)}"

    @ai_group.command(name="ask", description="GitHubç›´çµAIã«è³ªå•ã—ã¾ã™")
    async def ask(self, interaction: discord.Interaction, prompt: str):
        await interaction.response.defer()
        answer = await self.generate_response(prompt)
        await interaction.followup.send(f"ğŸ¤– **GitHub AI:**\n{answer[:1900]}")

async def setup(bot):
    await bot.add_cog(AIChat(bot))
